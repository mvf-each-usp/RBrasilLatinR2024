---
title: "A Comunidade `R Brasil` no Telegram"
author:
  - Marcelo Ventura Freire
  - Leonardo Fernandes Nascimento
format: 
  html:
    toc: true
---

```{r}
#| label: setup
#| include: false

library(tidyverse)
library(plotly)

## ver se precisa mesmo destes pacotes ----
# library(abjutils)
# library(viridis)
```

## Exploração Preliminar da Raspagem da Troca de Mensagens do Grupo


```{r}
#| label: monta-tabelas

# carrega a raspagem ----
raspagem <- 
  readRDS("./data/raspagem.rds") |> 
  group_split(tipo) 
## e já separa em três grupos pelo tipo: entrada, postagem e service
names(raspagem) <- map_chr(raspagem, \(tab) tab$tipo[1])
sapply(raspagem, nrow)
```


```{r}
#| label: graficos

# Summarize the data and filter for top 15 users
plot1 <- 
  raspagem$postagem |> 
  # filter(autor != "Deleted Account") |> 
  group_by(autor) |>
  summarize(n = n()) |>
  ungroup() |>
  top_n(15, n) |>
  mutate(autor = reorder(autor, -n)) |> 
  ggplot() +
  aes(x = autor, y = n, fill = factor(autor)) +
  geom_bar(stat = "identity", color = 'black', size = 0.2) + # Black border for contrast
  xlab("") +  # Custom label
  ylab("") +
  ggtitle("Top 15 Usuários do Telegram R-Brasil por Total de Mensagens") +
  coord_flip() +
  scale_fill_viridis_d(option = "viridis") +  # Apply the viridis color palette
  theme_void(base_size = 15) +  # Clean theme with increased base font size
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 18),  # Center and bold title
    axis.title.x = element_text(face = "bold", size = 14),  # Bold X axis label
    axis.title.y = element_text(face = "bold", size = 14),  # Bold Y axis label
    axis.text.x = element_text(size = 12),  # Size of X axis text
    axis.text.y = element_text(size = 12),  # Size of Y axis text
    panel.grid.major.y = element_blank(),  # Remove major gridlines on Y axis
    panel.grid.minor.y = element_blank(),  # Remove minor gridlines on Y axis
    panel.grid.major.x = element_line(color = "gray", linewidth = 0.5),  # Light gridlines on X axis
    legend.position = "none"  # Hide legend to focus on bar colors
  )
# Convert the ggplot to a Plotly plot
plotly_plot1 <- ggplotly(plot1)
# Display the Plotly plot
plotly_plot1


## Total de mensagens ao longo do tempo

plot2 <- 
  raspagem$postagem |> 
  mutate(mes = data |> floor_date("months")) |>
  count(mes) |>
  ggplot(aes(x = mes, y = n)) +
  geom_line(color = "darkblue", size = 1) +  # Line color and thickness
  geom_point(color = "darkred", size = 3) +  # Point color and size
  xlab("") +
  ylab("") +
  ggtitle("Total de mensagens no Telegram do R-Brasil") +
  theme_gray(base_size = 16)  # Apply the gray theme with a base font size

# Convert the ggplot to a Plotly plot
plotly_plot2 <- ggplotly(plot2)

# Display the Plotly plot
plotly_plot2

### total de mensagens por user ao longo do tempo
df |>
  dplyr::filter(nome != "Deleted Account") |>
  dplyr::mutate(nome = forcats::fct_lump(nome, 12),
                nome = as.character(nome),
                mes = lubridate::floor_date(data_hora, "month")) |>
  dplyr::filter(nome != "Other") |>
  dplyr::count(mes, nome, sort = TRUE) |>
  tidyr::complete(mes, nome, fill = list(n = 0)) |>
  ggplot(aes(x = mes, y = n)) +
  geom_line() +
  facet_wrap(~nome) +
  labs(x = "Mês", y = "Quantidade de mensagens") +
  ggtitle("Frequência de mensagens por usário no R-Brasil")+
  theme_bw()

## hora que mais interagimos

df |>
  dplyr::mutate(hora = factor(lubridate::hour(data_hora))) |>
  ggplot(aes(x = hora)) +
  geom_bar(fill = "royalblue") +
  theme_minimal(14) +
  ylab("Número de Mensagens")+
  ggtitle("Hora das mensagens no Telegram do R-Brasil")


## o dia da semana

df |>
  dplyr::mutate(wd = lubridate::wday(data_hora, label = TRUE)) |>
  ggplot(aes(x = wd)) +
  geom_bar(fill = "blue") +
  theme_minimal(14) +
  ylab("Dia da semana")+
  ggtitle("Dia da semana das mensagens")


# dá pra criar funções anônimas assim ;)
# esse é um limpador bem safado que fiz em 1 min
limpar <- . |>
  abjutils::rm_accent() |>
  stringr::str_to_title() |>
  stringr::str_remove_all("[^a-zA-Z0-9 ]") |>
  stringr::str_remove_all("Pra") |>
  stringr::str_squish()
library('abjutils')
# tirar palavras que nao quero
banned <- tidytext::get_stopwords("pt") |>
  dplyr::mutate(palavra = limpar(word))

cores <- viridis::viridis(10, begin = 0, end = 0.8)

df |>
  tidytext::unnest_tokens(palavra, texto) |>
  dplyr::mutate(palavra = limpar(palavra)) |>
  dplyr::anti_join(banned, "palavra") |>
  dplyr::count(palavra, sort = TRUE) |>
  with(wordcloud::wordcloud(
    palavra, n, scale = c(5, .1),
    min.freq = 80, random.order = FALSE,
    colors = cores
  ))

```




## TO-DO LIST

- fazer um histórico breve do grupo
    - ver se dá para levantar dados históricos da evolução do grupo, como 
        - evolução do número de membros
        - evolução do número de mensagens
- ver como aproveitar os dois scripts do Koselleck na 
  [Seção *Scripts do Koselleck*](Scripts-do-Koselleck)
- ver se ainda há algo a aproveitar no script do Trecenti na 
  [Seção](Scripts do Trecenti)
    - incluir referência ao [trabalho do Trecenti sobre a R Brasil](https://blog.curso-r.com/posts/2019-09-10-rbrasil/)
- ver se tem algo que dê pra aproveitar da [minha participação sobre comunidades na SatRday 2019](https://saopaulo2019.satrdays.org/)
    - não, não tem o que aproveitar: foi uma roda de conversa e não preparei nenhum material ou apresentação
    - só tenho material da apresentação sobre R Markdown
    - a o que falei da R Brasil foi só falado =/
- tópicos a mencionar
    - histórico do grupo
    - interesses do grupo
    - composição do grupo
    - ??? o quê mais?
        - minha pergunta mais respostas do Charles no `rbrasil-admins`
            - Gente, será que dá para fazer animação de word cloud? Se tem algum jeito de gerar word cloud com alguma forma de continuidade no posicionamento das palavras ao longo do tempo?
            - Se existe uma maneira, o craque da posição ( @Koselleck ) saberá
            - <https://stackoverflow.com/questions/61132650/is-there-a-way-to-animate-a-word-cloud-in-r>
            - e um bar-chart-race? como isso aqui:
              <https://github.com/corydonbaylor/barchart-race>
        - sugestão do [Marcus](https://t.me/marcusvvl)
            - usar a imagem do cachorro como capa do trabalho  
            ![catioRinho](img/catioRo.jpg)
        - sugestões do [Charles Santana](https://t.me/BrownSantana): 
            - Seria legal dar uma amostra das iniciativas que surgiram a partir do R-Brasil. Por exemplo, alguns grupos foram formados por pessoas interessadas em diferentes nichos, cito alguns:
                a) Web-scraping Brasil (https://t.me/+Z4d0O-ZQXsQyNDJk)
                b) Bio-R
                c) Shiny Brasil (https://t.me/shinybrasil)
                d) Dadoscope (https://revistaforum.com.br/opiniao/2019/7/10/dadoscope-novo-blog-na-forum-traz-jornalismo-de-dados-58299.html)
                e) BIT Analytics (startup criada por Tarssio e Italo com a colaboração de @Koselleck)
                f) Inúmeras colaborações em formato freelance em conjunto entre membros do grupo que mal se conhecem em pessoa (só eu já trabalhei com Tarssio, @oMarceloVentura , Marcelo Ventura -- o outro, com Neto Ferraz, @Koselleck, @FBarbalho, Arles e muitos conhecidos destas pessoas de 2017 até agora)
            - Seria legal também identificar o volume de novos membros por dia/mes/ano... se não for possível identificar essa informação com o R podíamos usar o bot do telegram mesmo. Vou procurar aqui
            - Por fim, acho que o mais importante é definir que história queremos contar. Queremos mostrar uma foto/perfil do R-Brasil? Queremos contar a História/Evolução do R-Brasil? 
            - Em qualquer gráfico que fale sobre o horário das mensagens, seria bom deixar claro de qual fuso-horário aquela mensagem se refere. Fuso horário do Brasil? UTC? Não sei na verdade qual é o fuso.
        - sugestões do [Adriano Mello](https://t.me/asmshark)
            - Uma comparação com o StackOverFlow seria bem legal. O grupo aqui é bem mais acessível e receptivo em comparação.



## Scripts do Koselleck

Reciclar depois: copy-pasta dos scripts do Koselleck


### script `etl.R`

```{r}
#| label: etl.R
#| eval: false
# lib
library(lubridate)
library(magrittr)
library(ggplot2)
library(tidyverse)
library(tidytext)
####$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
#### Read exported messages of Telegram  ##############
####$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
parser_telegram <- function(html_file) {
  # pega todas as mensagens
  divs <- xml2::read_html(html_file) |>
    xml2::xml_find_all("//div[@class='message default clearfix']")
  # nome da pessoa
  nomes <- divs |>
    xml2::xml_find_all("./div/div[@class='from_name']") |>
    xml2::xml_text() |>
    stringr::str_squish()
  # data e hora da mensagem
  data_horas <- divs |>
    xml2::xml_find_all("./div/div[@class='pull_right date details']") |>
    xml2::xml_attr("title") |>
    lubridate::dmy_hms()
  # texto da mensagem
  textos <- divs |>
    purrr::map(xml2::xml_find_first, "./div/div[@class='text']") |>
    purrr::map_chr(xml2::xml_text) |>
    stringr::str_squish()
  # retorna numa tabela
  tibble::tibble(
    data_hora = data_horas,
    nome = nomes,
    texto = textos
  )
}

## path (deletei os dados para nao ocupar mem do github)
path <- "./raw/ChatExport_2024-08-18/"

### list de arquivos com as msgs
messages <- fs::dir_ls(path, regexp = "messages")

### df 05-01-2021
df <- purrr::map_dfr(
  messages,
  parser_telegram,
  .id = "arquivo")
########## rds
saveRDS("df", file = "./data/df.rds")

```

### script `plots.R`

```{r}
#| label: plots.R
#| eval: false
# remove and clean
# rm(list=ls())
gc()
# lib
library(tidyverse)
library(plotly)
library(dplyr)
library(viridis)
### load data

df <- readRDS("./data/df.rds")

# Summarize the data and filter for top 15 users
plot1 <- df |>
  group_by(nome) |>
  summarize(n = n()) |>
  ungroup() |>
  top_n(15, n) |>
  ggplot(aes(x=reorder(nome, -n), y=n, fill=factor(nome))) +
  geom_bar(stat = "identity", color='black', size=0.2) +  # Black border for contrast
  xlab("") +  # Custom label
  ylab("") +
  ggtitle("Top 15 Usuários do Telegram R-Brasil por Total de Mensagens") +
  coord_flip() +
  scale_fill_viridis_d(option = "viridis") +  # Apply the viridis color palette
  theme_void(base_size = 15) +  # Clean theme with increased base font size
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 18),  # Center and bold title
    axis.title.x = element_text(face = "bold", size = 14),  # Bold X axis label
    axis.title.y = element_text(face = "bold", size = 14),  # Bold Y axis label
    axis.text.x = element_text(size = 12),  # Size of X axis text
    axis.text.y = element_text(size = 12),  # Size of Y axis text
    panel.grid.major.y = element_blank(),  # Remove major gridlines on Y axis
    panel.grid.minor.y = element_blank(),  # Remove minor gridlines on Y axis
    panel.grid.major.x = element_line(color = "gray", size = 0.5),  # Light gridlines on X axis
    legend.position = "none"  # Hide legend to focus on bar colors
  )

# Convert the ggplot to a Plotly plot
plotly_plot <- ggplotly(plot1)

# Display the Plotly plot
plotly_plot


## Total de mensagens ao longo do tempo

plot2 <- df |>
  dplyr::mutate(mes = lubridate::floor_date(data_hora, "month")) |>
  dplyr::count(mes) |>
  ggplot(aes(x = mes, y = n)) +
  geom_line(color = "darkblue", size = 1) +  # Line color and thickness
  geom_point(color = "darkred", size = 3) +  # Point color and size
  xlab("") +
  ylab("") +
  ggtitle("Total de mensagens no Telegram do R-Brasil") +
  theme_gray(base_size = 16)  # Apply the gray theme with a base font size

# Convert the ggplot to a Plotly plot
plotly_plot2 <- ggplotly(plot2)

# Display the Plotly plot
plotly_plot2

### total de mensagens por user ao longo do tempo
df |>
  dplyr::filter(nome != "Deleted Account") |>
  dplyr::mutate(nome = forcats::fct_lump(nome, 12),
                nome = as.character(nome),
                mes = lubridate::floor_date(data_hora, "month")) |>
  dplyr::filter(nome != "Other") |>
  dplyr::count(mes, nome, sort = TRUE) |>
  tidyr::complete(mes, nome, fill = list(n = 0)) |>
  ggplot(aes(x = mes, y = n)) +
  geom_line() +
  facet_wrap(~nome) +
  labs(x = "Mês", y = "Quantidade de mensagens") +
  ggtitle("Frequência de mensagens por usário no R-Brasil")+
  theme_bw()

## hora que mais interagimos

df |>
  dplyr::mutate(hora = factor(lubridate::hour(data_hora))) |>
  ggplot(aes(x = hora)) +
  geom_bar(fill = "royalblue") +
  theme_minimal(14) +
  ylab("Número de Mensagens")+
  ggtitle("Hora das mensagens no Telegram do R-Brasil")


## o dia da semana

df |>
  dplyr::mutate(wd = lubridate::wday(data_hora, label = TRUE)) |>
  ggplot(aes(x = wd)) +
  geom_bar(fill = "blue") +
  theme_minimal(14) +
  ylab("Dia da semana")+
  ggtitle("Dia da semana das mensagens")


# dá pra criar funções anônimas assim ;)
# esse é um limpador bem safado que fiz em 1 min
limpar <- . |>
  abjutils::rm_accent() |>
  stringr::str_to_title() |>
  stringr::str_remove_all("[^a-zA-Z0-9 ]") |>
  stringr::str_remove_all("Pra") |>
  stringr::str_squish()
library('abjutils')
# tirar palavras que nao quero
banned <- tidytext::get_stopwords("pt") |>
  dplyr::mutate(palavra = limpar(word))

cores <- viridis::viridis(10, begin = 0, end = 0.8)

df |>
  tidytext::unnest_tokens(palavra, texto) |>
  dplyr::mutate(palavra = limpar(palavra)) |>
  dplyr::anti_join(banned, "palavra") |>
  dplyr::count(palavra, sort = TRUE) |>
  with(wordcloud::wordcloud(
    palavra, n, scale = c(5, .1),
    min.freq = 80, random.order = FALSE,
    colors = cores
  ))

```



## Scripts do Trecenti

Reciclar depois: copy-pasta do script do Trecenti disponibilizado na 
[página do curso-r](https://blog.curso-r.com/posts/2019-09-10-rbrasil/)

```{r}
#| eval: false
library(magrittr)

ler_html_telegram <- function(html_file) {
  # pega todas as mensagens
  divs <- xml2::read_html(html_file) |> 
    xml2::xml_find_all("//div[@class='message default clearfix']")
  
  # nome da pessoa
  nomes <- divs |> 
    xml2::xml_find_all("./div/div[@class='from_name']") |> 
    xml2::xml_text() |> 
    stringr::str_squish()
  
  # data e hora da mensagem
  data_horas <- divs |> 
    xml2::xml_find_all("./div/div[@class='pull_right date details']") |> 
    xml2::xml_attr("title") |> 
    lubridate::dmy_hms()
  
  # texto da mensagem
  textos <- divs |> 
    purrr::map(xml2::xml_find_first, "./div/div[@class='text']") |> 
    purrr::map_chr(xml2::xml_text) |> 
    stringr::str_squish()
  
  # retorna numa tabela
  tibble::tibble(
    data_hora = data_horas,
    nome = nomes,
    texto = textos
  )
}
```

```{r}
#| eval: false
path <- "~/Downloads/Telegram Desktop/ChatExport_17_08_2019/"
todos_arquivos <- fs::dir_ls(path, regexp = "messages")

d_msg <- purrr::map_dfr(
  todos_arquivos, 
  ler_html_telegram, 
  .id = "arquivo"
)
```

```{r}
#| eval: false
d_msg |> 
  dplyr::count(nome, sort = TRUE) |> 
  dplyr::mutate(prop = scales::percent(n/sum(n))) |> 
  head(10) |> 
  knitr::kable()
```

```{r}
#| eval: false
library(ggplot2)
d_msg |> 
  dplyr::mutate(mes = lubridate::floor_date(data_hora, "month")) |> 
  dplyr::count(mes) |> 
  ggplot(aes(x = mes, y = n)) +
  geom_line() +
  geom_point() +
  theme_minimal(16)
```

```{r}
#| eval: false
d_msg |> 
  dplyr::filter(nome != "Deleted Account") |> 
  dplyr::mutate(nome = forcats::fct_lump(nome, 12),
                nome = as.character(nome),
                mes = lubridate::floor_date(data_hora, "month")) |> 
  dplyr::filter(nome != "Other") |> 
  dplyr::count(mes, nome, sort = TRUE) |> 
  tidyr::complete(mes, nome, fill = list(n = 0)) |> 
  ggplot(aes(x = mes, y = n)) +
  geom_line() +
  facet_wrap(~nome) +
  labs(x = "Mês", y = "Quantidade de mensagens") +
  theme_bw()
```

```{r}
#| eval: false
d_msg |> 
  dplyr::mutate(hora = factor(lubridate::hour(data_hora))) |> 
  ggplot(aes(x = hora)) +
  geom_bar(fill = "royalblue") +
  theme_minimal(14) +
  ggtitle("Hora das mensagens")
```

```{r}
#| eval: false
d_msg |> 
  dplyr::mutate(wd = lubridate::wday(data_hora, label = TRUE)) |> 
  ggplot(aes(x = wd)) +
  geom_bar(fill = "pink2") +
  theme_minimal(14) +
  ggtitle("Dia da semana das mensagens")
```

```{r}
#| eval: false
# dá pra criar funções anônimas assim ;)
# esse é um limpador bem safado que fiz em 1 min
limpar <- . |> 
  abjutils::rm_accent() |> 
  stringr::str_to_title() |> 
  stringr::str_remove_all("[^a-zA-Z0-9 ]") |> 
  stringr::str_squish()

# tirar palavras que nao quero
banned <- tidytext::get_stopwords("pt") |> 
  dplyr::mutate(palavra = limpar(word))

cores <- viridis::viridis(10, begin = 0, end = 0.8)

d_msg |> 
  tidytext::unnest_tokens(palavra, texto) |> 
  dplyr::mutate(palavra = limpar(palavra)) |> 
  dplyr::anti_join(banned, "palavra") |> 
  dplyr::count(palavra, sort = TRUE) |> 
  with(wordcloud::wordcloud(
    palavra, n, scale = c(5, .1), 
    min.freq = 80, random.order = FALSE,
    colors = cores
  ))
```



